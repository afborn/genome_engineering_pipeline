{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpe module\n",
    "#import for retrieving predicted gRNAs\n",
    "from pybiomart import Server\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import os\n",
    "import fnmatch\n",
    "# import nest_asyncio\n",
    "# nest_asyncio.apply()\n",
    "from selenium import webdriver\n",
    "import time\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.options.display.max_columns = None\n",
    "# pd.options.display.max_colwidth = 200\n",
    "#imports for primer design\n",
    "from Bio.Seq import Seq\n",
    "import primer3\n",
    "import numpy as np\n",
    "import requests\n",
    "import sys\n",
    "#imports for identifying knockout clones with seq \n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# define functions\n",
    "\n",
    "def check_csv_file(file):    \n",
    "    df_from_file = pd.read_csv(file)    \n",
    "    try:\n",
    "        df_from_file.columns = df_from_file.columns.str.upper()\n",
    "    except:\n",
    "        raise SystemExit(\"Problem with csv file\")        \n",
    "    try:\n",
    "        if 'GENE ID' in df_from_file.columns:\n",
    "            df_from_file['GENE ID'] = df_from_file['GENE ID'].str.upper()\n",
    "    except:\n",
    "        raise SystemExit(\"Please provide a csv file containing column named 'GENE ID'\")\n",
    "    try:\n",
    "        number_of_ensg_entries = df_from_file['GENE ID'].str.contains('ENSG').sum()\n",
    "        if not len(df_from_file) == (number_of_ensg_entries):\n",
    "            raise SystemExit(\"Please check that supplied csv file contains a column named 'GENE ID'\")\n",
    "    except:\n",
    "        raise SystemExit(\"Program aborted - please retry\")\n",
    "    \n",
    "    print(\"Successfully processed csv file\")\n",
    "    \n",
    "    return df_from_file\n",
    "\n",
    "\n",
    "def extract_gene_name_from_id(csv_file_ens_gene_id, dataset='hsapiens_gene_ensembl'):\n",
    "    '''Function to extract gene names using gene ids.\n",
    "    Function accepts a dataframe that is supplied by user and that \n",
    "    contains ENSEMBL gene ids in a column labeled \"Gene id\".\n",
    "    Function will test for existence of column \"Gene id\", prior to extracting gene names \n",
    "    (and gene ids) using Biomart Ensembl server.\n",
    "    Function returns a dataframe containing ENSEMBL gene id's and gene names.\n",
    "    '''\n",
    "    #initiate dict to store gene sequences for ENSEMBL names\n",
    "    gene_id = []\n",
    "    gene_symbol = []\n",
    "    \n",
    "    #check if supplied csv correct as df \n",
    "    df_ens_gene_name = check_csv_file(csv_file_ens_gene_id)   \n",
    "    \n",
    "    try:\n",
    "        #connect to Biomart Server\n",
    "        server = Server(host='http://www.ensembl.org')\n",
    "        # use #dataset.list_filters() to see available filters for list_filters method\n",
    "        #dataset.list_filters()\n",
    "        #generate dataset (homo sapiens)\n",
    "        dataset = (server.marts['ENSEMBL_MART_ENSEMBL']\n",
    "                   .datasets[dataset])\n",
    "        \n",
    "        for entry in range(len(df_ens_gene_name)):\n",
    "            try:\n",
    "                gene_ens_id = df_ens_gene_name[\"GENE ID\"].iloc[entry]\n",
    "                #parse dataset for gene_id\n",
    "                data_gene = dataset.query(attributes=['ensembl_gene_id', 'external_gene_name'],\n",
    "                              filters={'link_ensembl_gene_id': gene_ens_id})\n",
    "\n",
    "                #if gene_id found and unique, return gene_id, gene_symbol\n",
    "                if len(data_gene.index) == 1:\n",
    "                    gene_id.append(data_gene.iat[0,0])\n",
    "                    gene_symbol.append(data_gene.iat[0,1])\n",
    "            except Exception:\n",
    "                    print(\"Bummer - that didn't work\")\n",
    "                \n",
    "    except:\n",
    "        raise SystemExit(\"Program aborted - unable to extract human gene names for supplied gene Id's\")\n",
    "        #abort\n",
    "    \n",
    "    df_all_search_results = pd.DataFrame(zip(gene_id, gene_symbol), columns=('GENE ID', 'GENE NAME'))\n",
    "    \n",
    "    df_gen_name_found = df_all_search_results[df_all_search_results['GENE NAME'].map(type) == str]\n",
    "    df_no_gen_name_found = df_all_search_results[df_all_search_results['GENE NAME'].map(type) != str]\n",
    "    \n",
    "    print(\"Successfully identified gene names from IDs\")\n",
    "    \n",
    "    return df_gen_name_found, df_no_gen_name_found \n",
    "\n",
    "\n",
    "\n",
    "def extract_gene_seq_from_ens_id(csv_file_ens_gene_id):        \n",
    "    #initiate dict to store gene sequences for ENSEMBL IDs\n",
    "    gene_sequences = []\n",
    "    gene_id = []\n",
    "        \n",
    "    #check if supplied csv file is ok\n",
    "    df_ens_gene_id = check_csv_file(csv_file_ens_gene_id)\n",
    "    \n",
    "    try:\n",
    "        #REST API python3 Ensembl\n",
    "        server = \"https://rest.ensembl.org\"\n",
    "        #extract unique gene IDs in case of redundant ENSG ID entries in df\n",
    "        unique_gene_IDs = df_ens_gene_id['GENE ID'].unique()\n",
    "            #loop through unique_gene_IDs and extract gene sequence from ensembl\n",
    "        for entry in unique_gene_IDs:\n",
    "            try:\n",
    "                ext = \"/sequence/id/\" + entry +\"?\"\n",
    "                # retrieve plain text gene sequence\n",
    "                r = requests.get(server+ext, headers={ \"Content-Type\" : \"text/plain\"})\n",
    "                # sanity check object r\n",
    "                if not r.ok:\n",
    "                    gene_sequences.append(\"NaN\")\n",
    "                    gene_id.append(entry)\n",
    "                    #r.raise_for_status()\n",
    "                    #sys.exit(\"Unable to retrieve gene sequences from Ensembl - please try again later\")\n",
    "                else:\n",
    "                    gene_sequences.append(r.text)\n",
    "                    gene_id.append(entry)\n",
    "            except Exception:\n",
    "                print(\"Bummer - that didn't work!\")\n",
    "    except:\n",
    "        raise SystemExit(\"Unable to retrieve gene sequences from Ensembl\")\n",
    "    \n",
    "    print(\"Successfully retrieved gene sequences from IDs\")\n",
    "    \n",
    "    return pd.DataFrame(zip(gene_id, gene_sequences), columns=('GENE ID', 'GENE SEQUENCES'))\n",
    "\n",
    "\n",
    "\n",
    "def construct_synthego_urls_gene_names_ids(df_ens_genes):\n",
    "    '''Function constructs & returns a dataframe (df) of Synthego website URLs used to predict gRNAs.\n",
    "    Function requires a df, comprising two columns labeled \"GENE ID\" and \"GENE NAME\"\n",
    "    Function returns a dataframe containing a URL for all genes specified in input df, as well as \n",
    "    related gene id and gene name.\n",
    "    '''\n",
    "    try:\n",
    "        #Capital letter column header\n",
    "        df_ens_genes.columns = df_ens_genes.columns.str.upper()\n",
    "        df_ens_genes[\"GENE ID\"] = df_ens_genes[\"GENE ID\"].str.upper()\n",
    "        df_ens_genes[\"GENE NAME\"] = df_ens_genes[\"GENE NAME\"].str.upper()\n",
    "    except:\n",
    "        raise SystemExit(\"Program aborted - dataframe does no contain correct column labels'\")\n",
    "        #abort\n",
    "    \n",
    "    urls = []\n",
    "    gene_id = []\n",
    "    gene_name = []\n",
    "    \n",
    "    for entry in range(len(df_ens_genes)):\n",
    "        url = 'https://design.synthego.com/#/design/results?genome=homo_sapiens_gencode_26_primary&nuclease=cas9&gene_id=' \\\n",
    "        +df_ens_genes[\"GENE ID\"].iloc[entry]+'&symbol='+df_ens_genes[\"GENE NAME\"].iloc[entry]\n",
    "        urls.append(url)\n",
    "        gene_id.append(df_ens_genes[\"GENE ID\"].iloc[entry])\n",
    "        gene_name.append(df_ens_genes[\"GENE NAME\"].iloc[entry])\n",
    "            \n",
    "    df_url = pd.DataFrame(zip(gene_id, gene_name, urls), columns=('GENE ID', 'GENE NAME', 'SYNTHEGO URL'))\n",
    "    \n",
    "    print(\"Successfully constructed URLs from gene names and gene id's for scraping predicted gRNAs\")\n",
    "    \n",
    "    return df_url\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict_gRNA_from_urls(df_genes_urls, path_to_gecko='D:\\geckodriver\\geckodriver.exe'):\n",
    "    '''Function requires a dataframe containing ENSEMBL gene ids, gene names and Synthego URLs used for gRNA predicitons\n",
    "    for respective genes. Required column labels = \"GENE ID\", \"GENE NAME\", \"SYNTHEGO URL\".\n",
    "    Function returns a dataframe with ENSEMBL gene id's, gene names and 4 predicted gRNAs per gene.\n",
    "    Using this function requires geckodriver and Firefox installed. \n",
    "    Function takes two arguments - 1. a dataframe that contains columns \"GENE ID\", \"GENE NAME\" and \"SYNTHEGO URL\", 2. absolute path to installed geckodriver (default value set)\n",
    "    '''\n",
    "    path_to_gecko = path_to_gecko\n",
    "    counter = len(df_genes_urls)\n",
    "    print(\"Retrieving gRNAs for \" + str(counter) + \" gene(s) \\nWorking...\")\n",
    "   \n",
    "    try:\n",
    "        #Capital letter column header\n",
    "        df_genes_urls.columns = df_genes_urls.columns.str.upper()\n",
    "    except:\n",
    "        raise SystemExit(\"Program aborted - dataframe does no contain correct column labels'\")\n",
    "        #abort\n",
    "    \n",
    "    #Store predictions and related gene ID's and gene names\n",
    "    gRNAs_synth_array = []\n",
    "    gene_id_array = []\n",
    "    gene_name_array = []\n",
    "    gene_name_no_gRNA_returned = []\n",
    "    gRNA_in_exon = []\n",
    "    \n",
    "    try:\n",
    "        for entry in range(len(df_genes_urls)):\n",
    "            url = df_genes_urls[\"SYNTHEGO URL\"].iloc[entry]\n",
    "            #suppress opening Firefox browser window\n",
    "            os.environ['MOZ_HEADLESS'] = '1'\n",
    "            # run firefox webdriver from executable path of your choice\n",
    "            driver = webdriver.Firefox(executable_path = path_to_gecko)\n",
    "            # get web page\n",
    "            driver.get(url)\n",
    "            #30 seconds wait to have page fully loaded - might need to increase time\n",
    "            time.sleep(20)\n",
    "            results = driver.find_elements(\"xpath\", \"//*[@class='ng-binding']\")\n",
    "            #extract gene symbol for respective entry\n",
    "            gene_symbol = df_genes_urls[\"GENE NAME\"].iloc[entry]\n",
    "            #extract gene id for respective entry\n",
    "            gene_id = df_genes_urls[\"GENE ID\"].iloc[entry]\n",
    "           \n",
    "            gRNAs_synth = []\n",
    "            gRNAs_synth_min = []\n",
    " \n",
    "            # loop over results\n",
    "            for result in results:\n",
    "                gRNAs_synth.append(result.text)\n",
    "            if len(gRNAs_synth) == 11:\n",
    "                #extract minimal information for predicted gRNAs\n",
    "                gRNAs_synth_min = gRNAs_synth[5:9]\n",
    "                gRNAs_synth_array.append(gRNAs_synth_min)\n",
    "                #add gene id and gene name to arrays for later zipping of df\n",
    "                for entry in range(4):\n",
    "                    gene_id_array.append(gene_id)\n",
    "                    gene_name_array.append(gene_symbol)\n",
    "            else:\n",
    "                print('No gRNA prediction returned')\n",
    "                gene_name_no_gRNA_returned.append(gene_symbol)\n",
    "                \n",
    "                                     \n",
    "            print(\"Closing connection\")\n",
    "            driver.quit()\n",
    "            \n",
    "            counter -= 1\n",
    "            if counter > 1:\n",
    "                print(\"Remaining gRNA predictions: \" + str(counter) + \" genes \\nWorking...\")\n",
    "            elif counter == 1:\n",
    "                print(\"Retrieving gRNA predictions for last gene \\n...almost there...\")\n",
    "                \n",
    "    except:\n",
    "        raise SystemExit(\"Failed to retrieve predicted gRNAs!\") \n",
    "    \n",
    "    \n",
    "    #flatten array gRNAs_synth_array\n",
    "    gRNAs_synth_array_final = [item for sublist in gRNAs_synth_array for item in sublist]\n",
    "\n",
    "    #put lists together into df\n",
    "    try:\n",
    "        df_predictions = pd.DataFrame(zip(gene_id_array, gene_name_array, gRNAs_synth_array_final), columns=('GENE ID', 'GENE NAME', 'PREDICTED GRNA'))\n",
    "    except:\n",
    "        raise SystemExit(\"Unable to construct dataframe with gRNA predictions!\")\n",
    "    \n",
    "    print(\"Predictions succesfully completed!\")\n",
    "    \n",
    "    return df_predictions, gene_name_no_gRNA_returned\n",
    "\n",
    "\n",
    "def gRNA_hybridisation(df_gRNA_seq):\n",
    "    '''Function to check if gRNA's sequence is identical to DNA coding strand, or non-coding-strand.\n",
    "    \n",
    "    In case, gRNA is identical in sequence to non-coding strand, the gRNA sequence will be reverse-complemented \n",
    "    to turn it into its coding-strand counterpart.\n",
    "    \n",
    "    The function takes 1 argument:\n",
    "    1) Requirement: a dataframe containing columns, \"GENE NAME\", \"PREDICTED GRNA\" (containing gRNA sequences), \"GENE ID\" \n",
    "    (containing ENSEMBL Gene ID's that are predicted to be targeted by gRNA) and related DNA sequences (\"GENE SEQUENCES)\".\n",
    "    Gene ID and Gene name according to ENSEMBL definitions.\n",
    "    \n",
    "    Function returns a dataframe containing the columns \"GENE ID\", \"PREDICTED GRNA\", \"PREDICTED GRNA_T\" & \n",
    "    \"GRNA CODING STRAND\" (sequence of gRNA on DNA coding strand), \"GRNA LOCATION\" (location of gRNA on DNA coding strand), \n",
    "    \"GRNA HYBRIDISATION\" (indicating which strand the \"PREDICTED GRNA\" is binding to - values either \"coding strand\" \n",
    "    or \"non-coding strand\")\n",
    "    '''  \n",
    "    \n",
    "    print(\"Starting gRNA analyses...\")\n",
    "    \n",
    "    try:\n",
    "        #Capital letter column header\n",
    "        df_gRNA_seq.columns = df_gRNA_seq.columns.str.upper()\n",
    "        df_gRNA_seq['GENE ID'] = df_gRNA_seq['GENE ID'].str.upper()\n",
    "        df_gRNA_seq['PREDICTED GRNA'] = df_gRNA_seq['PREDICTED GRNA'].str.upper()\n",
    "        #replace U with T in gRNA sequences\n",
    "        df_gRNA_seq[\"PREDICTED GRNA_T\"] = df_gRNA_seq[\"PREDICTED GRNA\"].str.replace(\"U\",'T')  \n",
    "    except:\n",
    "        raise SystemExit(\"Dataframe does not contain correct column labels or column entries!\")\n",
    "        \n",
    "    try:\n",
    "        #array for storing orientation result\n",
    "        for_rev_orientation_gRNA = []\n",
    "\n",
    "        #using .find to match GRNA_T to gene sequence - if not found output will be -1.\n",
    "        for row in range(len(df_gRNA_seq)):\n",
    "            #get key from gRNA_predicted to retrieve value from gene_sequences dict\n",
    "            #key = df_gRNA_seq[\"GENE ID\"].iloc[row]\n",
    "            value = df_gRNA_seq[\"GENE SEQUENCES\"].iloc[row]\n",
    "            orientation = value.find(df_gRNA_seq[\"PREDICTED GRNA_T\"].iloc[row])\n",
    "            for_rev_orientation_gRNA.append(orientation)\n",
    "\n",
    "        #add for_rev_orientation_gRNA to df_gRNAs\n",
    "        df_gRNA_seq[\"for_rev_gRNA\"] = for_rev_orientation_gRNA\n",
    "\n",
    "        #create column and pre-populate\n",
    "        df_gRNA_seq[\"GRNA CODING STRAND\"] = df_gRNA_seq[\"PREDICTED GRNA_T\"]\n",
    "\n",
    "        #In case of output -1 in for_rev_orientation_gRNA use reverse complement gRNA to search for match\n",
    "        for entry in range(len(df_gRNA_seq)):\n",
    "            #check if column \"for_rev_gRNA\" contains -1, if so reverse complement the PREDICTED GRNA_T sequence and\n",
    "            #store it in GRNA ON CODING STRAND\n",
    "            print(entry)\n",
    "            if df_gRNA_seq.iloc[entry, 5] == -1:\n",
    "                df_gRNA_seq[\"GRNA CODING STRAND\"].iloc[entry] = Seq(df_gRNA_seq[\"PREDICTED GRNA_T\"].iloc[entry]).reverse_complement()\n",
    "                df_gRNA_seq[\"GRNA CODING STRAND\"].iloc[entry] = str(df_gRNA_seq[\"GRNA CODING STRAND\"].iloc[entry])\n",
    "\n",
    "        #determine gRNA position on coding strand\n",
    "        forward_position = []\n",
    "        #determine location of gRNA on coding strand\n",
    "        for row in range(len(df_gRNA_seq)):\n",
    "            #get key from gRNA_predicted to retrieve value from gene_sequences dict\n",
    "            #key = df_gRNA_seq[\"GENE ID\"].iloc[row]\n",
    "            value = df_gRNA_seq[\"GENE SEQUENCES\"].iloc[row]\n",
    "            orientation = value.find(df_gRNA_seq[\"GRNA CODING STRAND\"].iloc[row])\n",
    "            forward_position.append(orientation)\n",
    "\n",
    "        #add for_rev_orientation_gRNA to df_gRNAs\n",
    "        df_gRNA_seq[\"GRNA LOCATION\"] = forward_position    \n",
    "\n",
    "        #create new column with empty strings\n",
    "        df_gRNA_seq[\"GRNA HYBRIDISATION\"] = \"\"\n",
    "\n",
    "        #In case of output -1 in for_rev_gRNA, enter value 'to coding strand' to entry, otherwise 'to non-coding strand'\n",
    "        for entry in range(len(df_gRNA_seq)):\n",
    "            if df_gRNA_seq.iloc[entry, 5] == -1:\n",
    "                df_gRNA_seq[\"GRNA HYBRIDISATION\"].iloc[entry] = \"to coding strand\"\n",
    "            else:\n",
    "                df_gRNA_seq[\"GRNA HYBRIDISATION\"].iloc[entry] = \"to non-coding strand\"\n",
    "\n",
    "        df_gRNA_orientation = df_gRNA_seq[[\"GENE ID\", \"GENE NAME\", \"PREDICTED GRNA\", \"GRNA LOCATION\", \"GRNA HYBRIDISATION\", \"GRNA CODING STRAND\", \\\n",
    "                                         \"PREDICTED GRNA_T\", \"GENE SEQUENCES\"]]\n",
    "    except:\n",
    "        raise SystemExit(\"Unable to create dataframe with information on gRNAs!\")\n",
    "       \n",
    "    print(\"Analyses of gRNA completed successfully!\")  \n",
    "    \n",
    "    return df_gRNA_orientation\n",
    "       \n",
    "\n",
    "def primer3_primer_around_gRNA(df_gRNAs_info, upstream_dist=250, downstream_dist=250):\n",
    "\n",
    "    #list to hold sequences\n",
    "    sequences_for_primer_design = []\n",
    "    \n",
    "    df_gRNAs_info[\"GRNA NAME\"] = df_gRNAs_info[\"GENE NAME\"] + '_loc_' + df_gRNAs_info[\"GRNA LOCATION\"].astype(str)\n",
    "\n",
    "    for row in range(len(df_gRNAs_info)):\n",
    "        beginning = df_gRNAs_info[\"GRNA LOCATION\"].iloc[row] - 250\n",
    "        end = df_gRNAs_info[\"GRNA LOCATION\"].iloc[row] + 250\n",
    "        key = df_gRNAs_info[\"GRNA NAME\"].iloc[row]\n",
    "        value = df_gRNAs_info[\"GENE SEQUENCES\"].iloc[row]\n",
    "        seq_slice = value[beginning:end]\n",
    "        sequences_for_primer_design.append(seq_slice)\n",
    "\n",
    "    df_gRNAs_info['SEQ SLICE'] = sequences_for_primer_design\n",
    "    \n",
    "    primer_designed = {}\n",
    "    primer_not_designed = {}\n",
    "    \n",
    "    for entry in range(len(df_gRNAs_info)):\n",
    "        \n",
    "        if len(df_gRNAs_info['SEQ SLICE'].iloc[entry]) == 500:\n",
    "                \n",
    "            seq_dict = {\n",
    "            'SEQUENCE_ID': df_gRNAs_info['PREDICTED GRNA'].iloc[entry],\n",
    "            'SEQUENCE_TEMPLATE': df_gRNAs_info['SEQ SLICE'].iloc[entry],\n",
    "            }\n",
    "            primer_designed[df_gRNAs_info['GRNA NAME'].iloc[entry]] = primer3.designPrimers(seq_dict,    \n",
    "            {\n",
    "                'PRIMER_OPT_SIZE': 20,\n",
    "                'PRIMER_PICK_INTERNAL_OLIGO': 1,\n",
    "                'PRIMER_INTERNAL_MAX_SELF_END': 8,\n",
    "                'PRIMER_MIN_SIZE': 18,\n",
    "                'PRIMER_MAX_SIZE': 25,\n",
    "                'PRIMER_OPT_TM': 60.0,\n",
    "                'PRIMER_MIN_TM': 57.0,\n",
    "                'PRIMER_MAX_TM': 63.0,\n",
    "                'PRIMER_MIN_GC': 20.0,\n",
    "                'PRIMER_MAX_GC': 80.0,\n",
    "                'PRIMER_MAX_POLY_X': 100,\n",
    "                'PRIMER_INTERNAL_MAX_POLY_X': 100,\n",
    "                'PRIMER_SALT_MONOVALENT': 50.0,\n",
    "                'PRIMER_DNA_CONC': 50.0,\n",
    "                'PRIMER_MAX_NS_ACCEPTED': 0,\n",
    "                'PRIMER_MAX_SELF_ANY': 12,\n",
    "                'PRIMER_MAX_SELF_END': 8,\n",
    "                'PRIMER_PAIR_MAX_COMPL_ANY': 12,\n",
    "                'PRIMER_PAIR_MAX_COMPL_END': 8,\n",
    "                'PRIMER_PRODUCT_SIZE_RANGE': [[375, 500]],\n",
    "            })\n",
    "            \n",
    "        else:\n",
    "            primer_not_designed[df_gRNAs_info['GRNA NAME'].iloc[entry]] = \"Couldn't design primers,\" \\\n",
    "            \"input gene sequence too short\"\n",
    "        \n",
    "    primer_df = pd.DataFrame.from_dict(primer_designed, orient='index')\n",
    "    primer_df[\"GRNA NAME\"] = primer_df.index\n",
    "    primer_df = primer_df[[\"GRNA NAME\", \"PRIMER_LEFT_0_SEQUENCE\", \"PRIMER_RIGHT_0_SEQUENCE\", \"PRIMER_PAIR_0_PRODUCT_SIZE\", \"PRIMER_LEFT_0\", \"PRIMER_RIGHT_0\", \"PRIMER_INTERNAL_0\", \"PRIMER_LEFT_0_TM\", \"PRIMER_RIGHT_0_TM\"]]\n",
    "    \n",
    "    no_primer_df = pd.DataFrame.from_dict(primer_not_designed, orient='index')\n",
    "    no_primer_df[\"GRNA NAME\"] = no_primer_df.index\n",
    "                                \n",
    "    return primer_df, no_primer_df\n",
    "\n",
    "   \n",
    "def split_fasta(file):\n",
    "    #split a fasta file and name files according to header\n",
    "    for record in SeqIO.parse(file, \"fasta\"):\n",
    "        identifier = record.id\n",
    "        with open(f\"{identifier}.txt\", \"a\") as f:\n",
    "            SeqIO.write(record, f, \"fasta\")\n",
    "            \n",
    "def edited_ko_clone(csv_file_with_gRNAs=None, searchstring='', searchstring_name='', directory=os.listdir(), not_found=True, found=True):\n",
    "    \n",
    "    '''Function to identify gRNAs and their reverse complement in sequencing files.\n",
    "    \n",
    "    The function accepts the following arguments:\n",
    "    - csv_file_with_gRNAs: a csv-file containing sequences of guide RNAs. Two columns are REQUIRED \"GRNA\" (containing \n",
    "    the guide RNA sequence(s), AND \"GRNA NAME\" containing labels for guide RNA sequence(s).\n",
    "    Default=None\n",
    "    - searchstring: accepts a guide RNA sequence (string) provided by user. Default=\"\"\n",
    "    - searchstring_name: if searchstring provided, users can provide a string to label the searchstring. Default=\"\"\n",
    "    - directory: users can specify a directory (full path) to search for relevant fasta files to use for guide RNA search.\n",
    "    Default=os.listdir() -> current directory\n",
    "    - not_found: Default=True; if True, the function will return the file names of fasta files that DO NOT \n",
    "    contain respective guide RNA sequence(s)\n",
    "    - found: Default=True; if True, the function will return the file names of fasta files that DO contain respective\n",
    "    guide RNA sequence(s)\n",
    "    \n",
    "    If users provide a csv file and a searchstring, the csv file takes precedence and searchstring will be ignored\n",
    "    \n",
    "    return value depends on optional paramter setting (see parameters: not_found; found)\n",
    "    - a df containing guide RNA sequence(s) and name of sequence fasta file(s) that contain guide RNA sequence(s)\n",
    "    - a df containing guide RNA sequence(s) and name of sequence fasta file(s) that DO NOT contain guide RNA sequence(s)\n",
    "    - both of the above df's\n",
    "    '''\n",
    "    \n",
    "    directory = directory\n",
    "    searchstring = searchstring\n",
    "    \n",
    "    gRNA_seq_found = []\n",
    "    gRNA_label_found = []\n",
    "    gRNA_seq_not_found = []\n",
    "    gRNA_label_not_found = []\n",
    "    file_name_not_found = []\n",
    "    file_name_found = []\n",
    "    \n",
    "    if csv_file_with_gRNAs:\n",
    "        searchstring=\"\"\n",
    "        df_gRNAs = pd.read_csv(csv_file_with_gRNAs)\n",
    "    elif searchstring:\n",
    "        csv_file_with_gRNAs = None\n",
    "        searchstring = str(searchstring)\n",
    "        searchstring_label = str(searchstring_name)\n",
    "    \n",
    "    #if csv file provided by user   \n",
    "    if csv_file_with_gRNAs:\n",
    "        for entry in range(len(df_gRNAs)):\n",
    "            guide_seq = df_gRNAs[\"GRNA\"].iloc[entry]\n",
    "            guide_seq = guide_seq.replace(\"U\",\"T\")\n",
    "            guide_name = df_gRNAs[\"GRNA NAME\"].iloc[entry]\n",
    "            guide_reverse_complement = Seq(guide_seq).reverse_complement()\n",
    "            guide_reverse_complement = str(guide_reverse_complement)\n",
    "            guide_reverse_complement = guide_reverse_complement.replace(\"U\",\"T\")\n",
    "            for fname in directory:\n",
    "                if os.path.isfile(fname):\n",
    "                    if fnmatch.fnmatch(fname, '*.txt'):\n",
    "                        #print(fname)\n",
    "                        # Full path\n",
    "                        f = open(fname, 'r')\n",
    "                        sequence = f.read().replace('\\n', '')\n",
    "                        if (guide_seq not in sequence) and (guide_reverse_complement not in sequence):\n",
    "                            gRNA_seq_not_found.append(guide_seq)\n",
    "                            gRNA_label_not_found.append(guide_name)\n",
    "                            file_name_not_found.append(fname)\n",
    "                        elif (guide_seq in sequence) or (guide_reverse_complement in sequence):\n",
    "                            gRNA_seq_found.append(guide_seq)\n",
    "                            gRNA_label_found.append(guide_name)\n",
    "                            file_name_found.append(fname)\n",
    "                        f.close()\n",
    "    elif searchstring:\n",
    "        guide_seq = searchstring\n",
    "        guide_seq = guide_seq.replace(\"U\",\"T\")     \n",
    "        guide_name = searchstring_label\n",
    "        guide_reverse_complement = Seq(guide_seq).reverse_complement()\n",
    "        guide_reverse_complement = str(guide_reverse_complement)\n",
    "        guide_reverse_complement = guide_reverse_complement.replace(\"U\",\"T\")\n",
    "            \n",
    "        for fname in directory:\n",
    "            if os.path.isfile(fname):\n",
    "                if fnmatch.fnmatch(fname, '*.txt'):\n",
    "                    # Full path\n",
    "                    f = open(fname, 'r')\n",
    "                    sequence = f.read().replace('\\n', '')\n",
    "                    if (guide_seq not in sequence) and (guide_reverse_complement not in sequence):\n",
    "                        gRNA_seq_not_found.append(guide_seq)\n",
    "                        gRNA_label_not_found.append(guide_name)\n",
    "                        file_name_not_found.append(fname)\n",
    "                        #print('string not found in file %s' % fname)\n",
    "                    elif (guide_seq in sequence) or (guide_reverse_complement in sequence):\n",
    "                        gRNA_seq_found.append(guide_seq)\n",
    "                        gRNA_label_found.append(guide_name)\n",
    "                        file_name_found.append(fname)\n",
    "                    f.close()\n",
    "                \n",
    "    df_found = pd.DataFrame(zip(gRNA_label_found, gRNA_seq_found, file_name_found), columns=('GRNA NAME', 'GRNA SEQ', 'CLONES'))\n",
    "    df_not_found = pd.DataFrame(zip(gRNA_label_not_found, gRNA_seq_not_found, file_name_not_found), columns=('GRNA NAME', 'GRNA SEQ', 'CLONES'))\n",
    "    \n",
    "    if (not_found == True) and (found == True):      \n",
    "        return df_not_found, df_found\n",
    "    elif (not_found == True) and (found == False):\n",
    "        return df_not_found\n",
    "    elif (not_found == False) and (found == True):\n",
    "        return df_found\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "#https://stackabuse.com/python-how-to-flatten-list-of-lists/\n",
    "def flatten_list(_2d_list):\n",
    "    flat_list = []\n",
    "    # Iterate through the outer list\n",
    "    for element in _2d_list:\n",
    "        if type(element) is list:\n",
    "            # If the element is of type list, iterate through the sublist\n",
    "            for item in element:\n",
    "                flat_list.append(item)\n",
    "        else:\n",
    "            flat_list.append(element)\n",
    "    return flat_list\n",
    "\n",
    "def add_seq_results_to_df(df):\n",
    "    '''Requires df to contain columns \"CLONES\" - function goes through text files\n",
    "    and extracts sequence for to add to df\"'''\n",
    "    df[\"SEQUENCE\"] = \"\"\n",
    "    for entry in range(len(df)):\n",
    "        fname = df[\"CLONES\"].iloc[entry]\n",
    "        f = open(fname, 'r')\n",
    "        sequence = f.readlines()\n",
    "        sequence = sequence[1:]\n",
    "        #sequence = flatten_list(sequence)\n",
    "        sequence = \"\".join(sequence)\n",
    "        sequence = sequence.replace(\" \", \"\")\n",
    "        sequence = sequence.replace(\"\\n\", \"\")\n",
    "        #print(sequence)\n",
    "        df[\"SEQUENCE\"].iloc[entry] = sequence\n",
    "    return df\n",
    "        \n",
    "def translate(seq):\n",
    "       \n",
    "    table = {\n",
    "        'ATA':'I', 'ATC':'I', 'ATT':'I', 'ATG':'M',\n",
    "        'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n",
    "        'AAC':'N', 'AAT':'N', 'AAA':'K', 'AAG':'K',\n",
    "        'AGC':'S', 'AGT':'S', 'AGA':'R', 'AGG':'R',                 \n",
    "        'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n",
    "        'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n",
    "        'CAC':'H', 'CAT':'H', 'CAA':'Q', 'CAG':'Q',\n",
    "        'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n",
    "        'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',\n",
    "        'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n",
    "        'GAC':'D', 'GAT':'D', 'GAA':'E', 'GAG':'E',\n",
    "        'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n",
    "        'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n",
    "        'TTC':'F', 'TTT':'F', 'TTA':'L', 'TTG':'L',\n",
    "        'TAC':'Y', 'TAT':'Y', 'TAA':'_', 'TAG':'_',\n",
    "        'TGC':'C', 'TGT':'C', 'TGA':'_', 'TGG':'W',\n",
    "    }\n",
    "    protein =\"\"\n",
    "    #if len(seq)%3 == 0:\n",
    "    for i in range(0, len(seq), 3):\n",
    "        codon = seq[i:i + 3]\n",
    "        if (len(codon) == 3) and codon in table.keys():\n",
    "            protein+= table[codon]\n",
    "    return protein\n",
    "    \n",
    "    \n",
    "def translate_df_entry_to_protein(df):\n",
    "    #https://stackoverflow.com/questions/49073217/how-to-use-biopython-to-translate-a-series-of-dna-sequences-in-a-fasta-file-and\n",
    "    '''takes a df and translates DNA sequence into protein.\n",
    "    \"CLONES\"'''\n",
    "    protein_seq = []\n",
    "    protein_seq_rev_complement = []\n",
    "    aa_seq = []\n",
    "    aa_seq_rev_complement = []\n",
    "    edited_clones = []\n",
    "    protein_seq_final = []\n",
    "    protein_seq_final_rev_complement = []\n",
    "    for row in range(len(df)):\n",
    "        dna_seqs = df[\"SEQUENCE\"].iloc[row]\n",
    "        # generate all translation frames\n",
    "        for i in range(3):\n",
    "            frames = dna_seqs[i:]\n",
    "            aa_seq.append(translate(frames))\n",
    "            frames_rev_complement = Seq(dna_seqs).reverse_complement()\n",
    "            frames_rev_complement = str(frames_rev_complement)\n",
    "            frames_rev_complement = frames_rev_complement[i:]\n",
    "            aa_seq_rev_complement.append(translate(frames_rev_complement))\n",
    "            edited_clones.append(df[\"CLONES\"].iloc[row])\n",
    "        protein_seq.append(aa_seq)\n",
    "        protein_seq_rev_complement.append(aa_seq_rev_complement)\n",
    "    \n",
    "    protein_seq_final = flatten_list(protein_seq)\n",
    "    protein_seq_rev_complement_final = flatten_list(protein_seq_rev_complement)\n",
    "        \n",
    "    df_aa = pd.DataFrame(zip(edited_clones, protein_seq_final, protein_seq_rev_complement_final), columns=('CLONES', 'AA_SEQ', 'AA_SEQ_REV_COMPL'))\n",
    "    return df_aa\n",
    "\n",
    "def extract_nt_from_sangerseq_around_grna(file, df, upstream_dist = 50, downstream_dist = 50):\n",
    "    '''Function to extract a DNA sequence around a gRNA site. \n",
    "    Requires a txt file containing wild type sanger seq results. txt file needs to contain \"wild\" in \n",
    "    name. df needs to contain a column \"GRNA NAME\" and \"GRNA SEQ\" (containing gRNA sequence).\n",
    "    \"'''\n",
    "    #open file, read text except first line\n",
    "    f = open(file, 'r')\n",
    "    sequence = f.readlines()\n",
    "    sequence = sequence[1:]\n",
    "    sequence = \"\".join(sequence)\n",
    "    sequence = sequence.replace(\" \", \"\")\n",
    "    sequence = sequence.replace(\"\\n\", \"\")\n",
    "    f.close()\n",
    "    \n",
    "    #extract unique guide sequences from df\n",
    "    df = df.drop_duplicates('GRNA NAME')\n",
    "    df[\"WT-SEQ \" + str(upstream_dist)] = ''\n",
    "    df[\"FIRST_20NT\"] = 0\n",
    "    df[\"LAST_20NT\"] = 0\n",
    "\n",
    "    #position_of_guide in seq\n",
    "    #position_of_guide = []\n",
    "        \n",
    "    for row in range(len(df)):\n",
    "        position_in_seq = sequence.find(df[\"GRNA SEQ\"].iloc[row])\n",
    "        #if forward guide seq not found in seq\n",
    "        if position_in_seq == -1:\n",
    "            entry_rc = Seq(df[\"GRNA SEQ\"].iloc[row]).reverse_complement()\n",
    "            entry_rc = str(entry_rc)\n",
    "            position_in_seq_rc = sequence.find(entry_rc)\n",
    "            #position_of_guide.append(position_in_seq_rc)\n",
    "            beginning = position_in_seq_rc - upstream_dist\n",
    "            end = position_in_seq_rc + downstream_dist\n",
    "            extract = sequence[beginning:end]\n",
    "            df[\"WT-SEQ \" + str(upstream_dist)].iloc[row] = extract\n",
    "            first_20_nt = extract[:20]\n",
    "            last_20_nt = extract[-20:]\n",
    "            df[\"FIRST_20NT\"].iloc[row] = first_20_nt\n",
    "            df[\"LAST_20NT\"].iloc[row] = last_20_nt            \n",
    "        else:\n",
    "            #position_of_guide.append(position_in_seq)\n",
    "            beginning = position_in_seq - upstream_dist\n",
    "            end = position_in_seq + downstream_dist\n",
    "            extract = sequence[beginning:end]\n",
    "            df[\"WT-SEQ \" + str(upstream_dist)].iloc[row] = extract\n",
    "            first_20_nt = extract[:20]\n",
    "            last_20_nt = extract[-20:]\n",
    "            df[\"FIRST_20NT\"].iloc[row] = first_20_nt\n",
    "            df[\"LAST_20NT\"].iloc[row] = last_20_nt            \n",
    "\n",
    "    return df\n",
    "\n",
    "                     \n",
    "if __name__ == \"__main__\":\n",
    "    print(\"This is just a module\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
